{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'module'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13572\\878823583.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlastdance\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAlgorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'module'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from kiwipiepy import Kiwi\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "from module.lastdance import Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "jh = JH()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"nnp_list.pkl\", \"rb\") as r :\n",
    "    nnp_list = pickle.load(r)\n",
    "\n",
    "with open(\"WD.StandardDict.p\", \"rb\") as r :\n",
    "    StandradDict = pickle.load(r)\n",
    "\n",
    "with open(r\"WD.WordToStandard.p\", \"rb\") as r :\n",
    "    WordToStandard = pickle.load(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Algorithm:\n",
    "    def __init__(self) -> None:\n",
    "        self.stop_words = [\"정식\",\"안주\"] \n",
    "        self.option_list = [\"추가\",\"선택\", \"많이\", \"적게\", \"조금\",\"빼고\", \"리필\", \"기본\"]\n",
    "\n",
    "\n",
    "    # stop words algorithm / Step 1 #\n",
    "    def is_stop_words(self, stop_word_text:str, stop_words_param:list) -> str:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            stop_word_text (str): _description_\n",
    "            stop_words_param (list): _description_\n",
    "\n",
    "        Returns:\n",
    "            str: _description_\n",
    "        \"\"\"\n",
    "        result = jh.kiwi.space(stop_word_text).split(\" \")\n",
    "        for i in result :\n",
    "            if i in stop_words_param :\n",
    "                pat = re.compile(f\"{i}\")\n",
    "                text = re.sub(pat, \"\", stop_word_text)\n",
    "        return text.strip()\n",
    "    # apply 선언 함수\n",
    "    stop_words_func = lambda self, txt : self.is_stop_words(txt, self.stop_words)\n",
    "    \n",
    "    # option check algorithm / Step 2 #\n",
    "    def is_option(self, option_text:str, option_li:list) ->str:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            option_text (str): _description_\n",
    "            option_li (list): _description_\n",
    "\n",
    "        Returns:\n",
    "            str: _description_\n",
    "        \"\"\"\n",
    "        result = jh.kiwi.space(option_text).split(\" \")\n",
    "        for i in result :\n",
    "            if i in option_li :\n",
    "                pat = re.compile(f\"{i}\")\n",
    "                valiable = \"\".join(pat.findall(option_text))\n",
    "                return \" \".join(result), f\"옵션 {valiable}\"\n",
    "    # apply 선언 함수\n",
    "    option_func = lambda self, txt : self.is_option(txt, self.option_list)\n",
    "\n",
    "    # special_character algorithm / Step 3 #\n",
    "    def special_char(self, special_text:str) -> str: \n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            special_text (str): _description_\n",
    "\n",
    "        Returns:\n",
    "            str: _description_\n",
    "        \"\"\"\n",
    "        split_result = re.split(r\"\\+|\\&|\\/|\\,\", special_text)\n",
    "        if len(split_result) >= 2 :\n",
    "            combine_text = [split_result[split_result.index(i)].strip() for i in split_result]\n",
    "            pattern = re.compile(r\"[^\\w\\s]+\")\n",
    "            return [pattern.sub(\"\", i ) for i in combine_text]\n",
    "        else : \n",
    "            pattern = re.compile(r\"[^\\w\\s]+\")\n",
    "            return jh.kiwi.space(pattern.sub(\"\", special_text))\n",
    "\n",
    "    # unit algorithm / Step 4 #\n",
    "    extract_morph = lambda self, x : jh.morph(x)\n",
    "\n",
    "    # space algorithm / Step 5 #\n",
    "    spacing_text = lambda self, x : jh.kiwi.space(x)\n",
    "\n",
    "    # remove_nnp/ Step 6 #\n",
    "    def nnp_extract(self, text:str, nnp_list:list) -> str :\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            text (str): _description_\n",
    "            nnp_list (list): _description_\n",
    "\n",
    "        Returns:\n",
    "            str: _description_\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        for i in text.split() :      \n",
    "            if i not in nnp_list :\n",
    "                res.append(i)\n",
    "        return \" \".join(res)\n",
    "\n",
    "    nnp_remove = lambda self, x: self.nnp_extract(x, nnp_list)\n",
    "\n",
    "\n",
    "    # std words / Step 7 #\n",
    "    def word_standard(self,txt:str) -> str :\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            txt (str): _description_\n",
    "\n",
    "        Returns:\n",
    "            str: _description_\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        for word in txt.split(' '):\n",
    "            try:\n",
    "                res.append(WordToStandard[word])\n",
    "            except :\n",
    "                res.append(word)\n",
    "        return \" \".join(res)\n",
    "        \n",
    "    # data standard / Step 8 #\n",
    "    def member_menu(self, txt:str) -> str :\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            txt (str): _description_\n",
    "\n",
    "        Returns:\n",
    "            str: _description_\n",
    "        \"\"\"\n",
    "        score_ls = []\n",
    "        word_ls = txt.split(' ')\n",
    "        for word in word_ls:\n",
    "            try:\n",
    "                score_ls.append(StandradDict[word]['mean'])\n",
    "            except:\n",
    "                score_ls.append(10)\n",
    "        return word_ls[np.array(score_ls).argmax()], word_ls[np.array(score_ls).argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = Algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13572\\3210714009.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0malgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmember_menu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"초콜릿 라떼\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13572\\4002350685.py\u001b[0m in \u001b[0;36mmember_menu\u001b[1;34m(self, txt)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                 \u001b[0mscore_ls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mword_ls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_ls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_ls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_ls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "algo.member_menu(\"초콜릿 라떼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 불용어 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\"정식\",\"안주\"]\n",
    "\n",
    "def is_stop_words(text, stop_words) :\n",
    "    result = jh.kiwi.space(text).split(\" \")\n",
    "    for i in result :\n",
    "        if i in stop_words :\n",
    "            pat = re.compile(f\"{i}\")\n",
    "            text = re.sub(pat, \"\", text)\n",
    "    return text.strip()\n",
    "\n",
    "func = lambda txt : is_stop_words(txt, stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 옵션 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "option_list = [\"추가\",\"선택\", \"많이\", \"적게\", \"조금\",\"빼고\", \"리필\"]\n",
    "def is_option(text, option_li) :\n",
    "    result = jh.kiwi.space(text).split(\" \")\n",
    "    for i in result :\n",
    "        if i in option_li :\n",
    "            pat = re.compile(f\"{i}\")\n",
    "            valiable = \"\".join(pat.findall(text))\n",
    "            return \" \".join(result), f\"옵션 {valiable}\"\n",
    "\n",
    "option_func = lambda txt : is_option(txt, option_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 특수문자 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def special_char(text) : \n",
    "    split_result = re.split(r\"\\+|\\&|\\/|\\,\", text)\n",
    "    if len(split_result) >= 2 :\n",
    "        combine_text = [split_result[split_result.index(i)].strip() for i in split_result]\n",
    "        pattern = re.compile(r\"[^\\w\\s]+\")\n",
    "        return [pattern.sub(\"\", i ) for i in combine_text]\n",
    "        # text_token = [j for i in kiwi.tokenize(combine_text) for j in i]\n",
    "        # cp = tuple(cp_data.form for cp_data in text_token if cp_data.tag.startswith(\"N\"))\n",
    "        # return cp\n",
    "    else : \n",
    "        pattern = re.compile(r\"[^\\w\\s]+\")\n",
    "        return jh.kiwi.space(pattern.sub(\"\", text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단위 처리 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('과자', '')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jh.morph(\"과자\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spacing aloritm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요 지금 이 문장은 스페이스 알고리즘입니다'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jh.kiwi.space(\"안녕하세요지금이문장은스페이스알고리즘입니다\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 고유명사 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnp_extract(text, nnp_list) :\n",
    "    res = []\n",
    "    # split_text = kiwi.space(text) \n",
    "    for i in text.split() :  \n",
    "    # for i in split_text.split() :    \n",
    "        if i not in nnp_list :\n",
    "            res.append(i)\n",
    "    return \" \".join(res)\n",
    "                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단어 표준화 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_standard(txt) :\n",
    "    res = []\n",
    "    for word in txt.split(' '):\n",
    "        try:\n",
    "            res.append(WordToStandard[word])\n",
    "        except :\n",
    "            res.append(word)\n",
    "    return \" \".join(res)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 표준화 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"아이스 카페라떼\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def member_menu(txt):\n",
    "    score_ls = []\n",
    "    word_ls = txt.split(' ')\n",
    "    for word in word_ls:\n",
    "        try:\n",
    "            score_ls.append(StandradDict[word]['mean'])\n",
    "        except:\n",
    "            score_ls.append(10)\n",
    "    return word_ls[np.array(score_ls).argmax()], word_ls[np.array(score_ls).argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = re.compile(r\"\\([^)]*\\)|\\[[^)]*\\]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[커피에반하다]', '(기본)']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat.findall(\"[커피에반하다] 허니버터브레드 (기본)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array = data.str.extractall(r\"(\\([^)]*\\)|\\[[^)]*\\]|\\([^)]\\([^)]\\))\").values\n",
    "my_list = my_array.tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
